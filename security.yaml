---
# vim node-security

    apiVersion: v1
    kind: pod
    metadata: 
      name: nodejs-sec-ctx
      spec:
        securityContext:
          runAsUser: 1000 # (uid) node user in nodejs container image
          runAsGroup: 3000 # (gid) 
          fsGroup: 2000 
        containers: 
        - name: nodejs-sec-ctx
          image: docker.io/node:latest
          command: [ 'sh', '-c', 'sleep 1h' ]
          securityContext:
            allowPriviledgeEscalation: false
            capabilities:
              add:
              - SYS_ADMIN
              - NET_ADMIN

# kubectl apply -f node-sec.yaml
# kubectl get pods
# kubectl exec -it nodejs-sec-ctx --sh
# kubectl get pod nodejs-sec-ctx -o yaml


---
# vim bb-cap.yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: bb-cap
    spec:
      containers:
        - name: bb-cap-container
          image: busybox:latest
          command: ["sleep", "3600"]
          securityContext:
            capabilities:
              add: ["CAP_CHOWN"]

# kubectl apply -f bb-cap.yaml
# kubectl get pods bb-cap -o yaml

--- 
# ubuntu-privileged

    apiVersion: v1
    kind: Pod
    metadata:
      name: ubuntu-privileged
    spec:
      containers:
        - name: ubuntu-privileged-container
          image: ubuntu:latest
          command: ["sleep", "3600"]
          securityContext:
            privileged: true

# kubectl apply -f ubuntu-privileged.yaml
# kubectl exec -it ubuntu-privileged -- /bin/bash
# apt-get update
# apt-get install libcap2-bin
# capsh --print

--- 
# application of security policies to namespaces 

# kubectl create namespace secure
# kubectl config set-context --current --namespace-secure
# kubectl label --overwrite namespace secure \
  # add 
    # pod-security.kubernetes.io/enforce=baseline \
    # pod-security.kubernetes.io/enforce-version=latest \
    # pod-security.kubernetes.io/warn=restricted \
    # pod-security.kubernetes.io/warn-version=latest \
    # pod-security.kubernetes.io/audit=restricted \
    # pod-security.kubernetes.io/audit-version=latest \
# kubectl run nginx --image nginx:latest --port 80

---
# oh-so-secure-nginx

    apiVersion: v1 
    kind: pod 
    metadata: 
      name: secure-nginx 
    spec: 
      containers:
      - name: secure-nginx-container
        image: nginx:latest 
        ports: 
        - containerPort: 80
        securityContext:
          allowPriviledgeEscalation: false 

# kubectl apply -f oh-so-secure.yaml

--- 
# Role-based access control (RBAC)

# kubectl create namespace system-01
# kubectl config get-contexts
# sudo useradd -s /bin/bash user1
# sudo passwd user1

# (Create ca certificate for the new user, user1)
# openssl genrsa -out user1.key 2048
# touch $HOME/ .rnd
# openssl req -key user1.key \
  # add (- out user1.csr -subj "CN=user1/O=system-01") (CN= common name ,O=organisation)
# sudo openssl x509 -req -in user1.csr \
  # -CA /etc/kubernetes/pki/ca.crt \
  # -CAkey /etc/kubernetes/pki/ca.key \
  # -CAcreateserial \ 
  # -out user1.crt -days 45

# (Set the user user1â€™s entry in kubeconfig)
# kubectl config set-credentials user1 \
  # --client-certificate=/home/one_ceru/user1.crt \
  # --client-key=/home/one_ceru/user1.key

# (set the user user1 context for the cluster)
# kubectl config set-context user1-context
  # --cluster=kubernetes \
  # --namespace=system-01 \
  # --user=user1

# kubectl config get-context

# kubectl get pods --context user1-context

--- 
# vim role.yaml (creation of role)

    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: viewer
      namespace: system-01
    
    rules:
      - apiGroups: ["", "apps"]
        resources: ["pods, "replicasets", "deployments"]
        verbs: ["list", "get", "watch"]

# kubectl apply -f role.yaml
# kubectl describe role viewer
#vim role-bind.yaml

    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: viewer-role-binding
      namespace: system-01
    
    subjects:
      - kind: user
        name: user1
        apiGroup: rbac.authorization.k8s.io
    
    roleRef:
      kind: Role
      name: viewer
      apiGroup: rbac.authorization.k8s.io

# kubectl apply -f role-bind.yaml
# kubectl get pods --context user1-context

--- # trobleshooting pods
# vim busybox-faulty.yaml
    
    apiVersion: v1
    kind: Pod
    metadata:
      name: busybox-faulty
    spec:
      containers:
        - name: busybox-faulty-container
          image: busybox:latest
 
# kubectl apply -f busybox-faulty.yaml
# kubectl get pods busybox-faulty
   # (crashloopbackoff state)

# edit the yaml file (add (command: ["sleep", "3600" ]) in container spec ) and re apply kubectl command
# guide 2,3,4 in troubleshoot (refer kh )


--- # k8s logs

# cd/var/log
# cd containers
# tree -a

# kubectl get pods --show-labels
# kubectl logs <pod name>
# kubectl logs -l <label name>
# kubectl logs <pod name> -c <container name>

--- # pod prioritity classes

# kubectl get priorityclasses.scheduling.k8s.io
# kubectl describe priorityclasses system-cluster-critical
# kubectl describe priorityclasses system-node-critical
# kubectl get pods --all-namespaces \
  # -o custom-columns='NAME'.metadata.name,PRIORITY:.Spec.priorityClassName'

--- # liveness and readiness probs

# probes

        apiVersion: v1 
        kind: pod
        metadata:
          name: test-probes
          labels:
            test: probes 
        spec: 
          containers: 
          - name: test-probe-container 
            image: registry.k8s.io/busybox
            command: ['/bin/sh', '-c', 'touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600']
            livenessProbe:
              exec:
                command: 
                - cat 
                - /tmp/healthy 
              initialDelaySeconds: 10
              periodSeconds: 10
        
            readinessProbe:
              exec:
                command:
                - cat
                - /tmp/healthy 
              initialDelaySeconds: 10
              periodSeconds: 10

# kubectl apply -f probes.yaml
# kubectl describe test-probes 

---
# init-nginx

        apiVersion: v1 
        kind: pod
        metadata:
          name: init-web
          labels:
            test: init-web  
        spec: 
          containers: 
          - name: name-application 
            image: nginx-latest
            volumrMounts:
              - name: nginx-logs
                mountPath: /var/log/nginx
          - name: busybox-sidecar
            image: busybox:latest
            command: ['sh', '-c', 'while true; do cat /var/log/nginx/access.log; sleep 30; done']
            volumeMounts:
              - name: nginx-logs
                mountPath: /var/log/nginx
          volumes: 
            -name: nginx-logs 
            emptyDir: {}
          
          initContainers:
            - name: busybox-init 
              image: busybox: latest
              command: ['sh', '-c', 'echo busyboc-init started...; sleep 5;echo busybox-init completed.;] 

# kubectl create -f init-nginx.yaml
# kubectl describe pod init-web
---

# pod-scheduling

        apiVersion: apps/v1
        kind: deployment
        metadata:
          name: deploy-01
            
        spec: 
          replicas: 5
          selector:
            matchLabels:
              app: v1 
          template:
            metadata:
              labels:  
                app: v1 
            spec:
              containers: 
              - name: deploy-01-container 
                image: nginx-latest
                ports:
                  - containerPort: 80 
              affinity:
                nodeAffinity:
                  requiredDuringSchedulingIgnoredDuringExecution:
                    nodeSelectorTerms:
                    - matchExpressions:
                      - key: kubernetes.io/hostname
                        operator: In
                        values:
                          -node-1

# kubectl apply-f scheduling.yaml
# kubectl aget deployments 


--- 
# alpine

        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: alpine
        
        spec:
          replicas: 2
          selector:
            matchLabels:
             app: alpine
          template:
            metadata:
              labels:
                app: alpine
            spec:
              containers:
                - name: alpine-container
                  image: alpine:latest
                  command: ['sleep', '3600']
                  ports:
                   - containerPort: 80
              tolerations:
              - key: "app"
                operator: "Equal"
                value: "alpine"
                effect: "NoSchedule"

# kubectl apply -f alpine.yaml

